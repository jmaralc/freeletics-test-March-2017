{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case of study 1\n",
    "\n",
    "Information about number of users, from:\n",
    "https://www.freeletics.com/en/press/wp-content/uploads/sites/24/2015/02/EN-Presskit-Febraury-2017_web.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as grds\n",
    "import scipy \n",
    "from scipy import signal as signal\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose meaningful numbers for X,Y,Z.\n",
    "\n",
    "The parameter X seems to be the arrival rate of users to the application. Because the total amount of Freeletics users is around 14 million of users. The estimation of having half of them having access to the feature in the same day seems reasonable.\n",
    "\n",
    "The parameter Y will model loading time without the feature. Because we want to have the servers working in a proper range of occupancy and user waiting time it is a good idea to fix the desired traffic intensity $\\rho$. If this factor is larger than one we could not provide service and if it is too small we are overstimating the users activity in our servers. Hence a value of $\\rho=0.8=\\frac{\\lambda}{\\mu}$ seems a good choice. Finally $Y=\\frac{1}{\\mu}$\n",
    "\n",
    "The parameter Z is the impact of the new feature in the model. Because we do not have any prior about it, I decided to model it as a normal distributed random variable with zero mean and standard deviation being a tenth of the loading time that the system have without the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=X= 81.0185185185  users/second\n",
      "mu= 101.273148148  users/second\n",
      "Y= 0.00987428571429  seconds\n",
      "Z= [ 0.00122791] seconds\n",
      "Beta= [ 0.00864637] seconds\n",
      "1/Beta= [ 115.65545436] users/seconds\n"
     ]
    }
   ],
   "source": [
    "# Defining the parameters of our model based on the data sources explained before\n",
    "# This section cover the question:\n",
    "# Choose meaningful numbers for X,Y,Z.\n",
    "\n",
    "Total_Customers = 14e6\n",
    "DailyCustomers = Total_Customers * 0.5 #Assuming half of the customers acces the application\n",
    "\n",
    "# The parameter X is related with the traffic incoming to the application server. It is the incoming rate\n",
    "X= DailyCustomers/ 24 / 3600 #users arrived per time unit (seconds)\n",
    "lambd = X\n",
    "\n",
    "# The parameter Y is related with the loading time of the service without the new feature.\n",
    "# Because we want to have a proper use of the server we assume traffic intensity to be 0.8\n",
    "rho=0.8\n",
    "mu = lambd/rho\n",
    "\n",
    "Y= 1.0/mu # ms per user\n",
    "\n",
    "# The parameter Z is related to the influence of the new feature in the server.\n",
    "#It will be modeled as a normal distribution with mean=0 and std = Y*0.1.\n",
    "# This assumes that the load of the feature will deviate one tenth of the original waiting time\n",
    "\n",
    "Z= np.random.normal(loc=0,scale=Y*0.1,size=1) # ms per user\n",
    "\n",
    "Beta = Y-Z\n",
    "\n",
    "print 'lambda=X=',X,' users/second'\n",
    "print 'mu=',1.0/Y,' users/second'\n",
    "print 'Y=',Y,' seconds'\n",
    "print 'Z=',Z,'seconds'\n",
    "print 'Beta=',Beta,'seconds'\n",
    "print '1/Beta=',1.0/Beta,'users/seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and visualize dummy data that models the scenario above over 24 hours. How did you model user traffic and SFLT? What parameters did you use? Why?\n",
    "\n",
    "The user traffic can be modeled as an homogeneus Poisson process. This choice makes sense in an arrival situation in which the arrival is memory less, that is there is independency of the events that arrived in the past to the system.Despite of this unrealistic situation, this assumption provides a big mathematical background for estimations and modeling of the whole system. The probability of having a given of arrivals is given by the Poisson distribution: \n",
    "\n",
    "$ Traffic = \\frac{(\\lambda t^n)}{n!} \\exp(-\\lambda t)$\n",
    "\n",
    "where the parameter $\\lambda$ is excatly the parameter X, i.e. the users (or arrival of users) per day. It can be checked that if the arrival process follows a Poisson distribution then the time between sucessive arrivals follows an exponential distribution with same paremeter as the Poisson distribution $\\lambda$.\n",
    "\n",
    "In the other hand, the capacity of the server to process the users requests will follow an exponential distribution with parameter $\\mu$\n",
    "\n",
    "The fact of having an poissonal arrival process and an exponential loading (serving) time together with a policy of FCFS (first-come, first-served) makes possible to model the whole system as a M/M/1 queue system. The advantages of this system, is that despite of its simplcity can provide a good estimator for measuring the impact of the new feature in the system.\n",
    "\n",
    "Under this assumptions the SFLT will follow an exponential distribution of scale factor Beta = Y-Z.\n",
    "\n",
    "$ SFLT = \\frac{1}{Y-Z} \\exp(-\\frac{1}{Y-Z} t)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T [    0     1     2 ..., 86397 86398 86399]\n",
      "Traffic [65 83 79 ..., 85 87 77]\n",
      "SFLT [[ 0.01398434  0.02442391  0.00333444 ...,  0.01015792  0.0256075\n",
      "   0.00609031]]\n",
      "E[SFLT] 0.00867698512491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fc17aab7ad0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'to_rgba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/home/javier/.pyenv/versions/2.7.13/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/javier/.pyenv/versions/2.7.13/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[0;32m/home/javier/.pyenv/versions/2.7.13/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'to_rgba'"
     ]
    }
   ],
   "source": [
    "# Generating the distributions of the data\n",
    "T = np.arange(24*3600)\n",
    "\n",
    "print 'T',T\n",
    "\n",
    "\n",
    "\n",
    "Arrival_process = np.random.poisson(lambd, size=(1,len(T))) # Poisson process with lambda value \n",
    "Traffic =Arrival_process[0]\n",
    "\n",
    "SFLT = np.random.exponential(scale=Beta, size=(1,len(T)))\n",
    "\n",
    "\n",
    "print 'Traffic',Traffic\n",
    "print 'SFLT',SFLT\n",
    "\n",
    "print 'E[SFLT]',np.mean(SFLT[0])\n",
    "\n",
    "\n",
    "\n",
    "# Definition of the figure.\n",
    "figid = plt.figure(1,figsize=(20, 10), dpi=180)\n",
    "# Definition of the matrix of plots. In this case the situation is more complex that is why I need to define a\n",
    "# matrix. It will be a dim[2x3] matrix.\n",
    "gs = grds.GridSpec(2,3)\n",
    "ax1 = plt.subplot(gs[0, :])\n",
    "ax2 = plt.subplot(gs[1,:])\n",
    "\n",
    "ax1.plot(T,Traffic,color='blue')\n",
    "ax2.plot(T,SFLT[0],color='orange')\n",
    "\n",
    "# Setting the xlabel with the desired parameters\n",
    "override = {\n",
    "    'fontsize'            : '14',\n",
    "    'verticalalignment'   : 'top',\n",
    "    'horizontalalignment' : 'center'\n",
    "    }\n",
    "ax1.set_xlabel('t[seconds]',override)\n",
    "ax2.set_xlabel('t[seconds]',override)\n",
    "\n",
    "ax1.set_ylabel('Incoming users',override)\n",
    "ax2.set_ylabel('SFLT [seconds]',override)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given the dummy data, formulate a hypothesis, to answer the question of “is the feature affecting the SFLT in any way?\n",
    "\n",
    "To check whether the feature is affecting the SFLT in any way it will be neccessary to set a null hypothesis $H_0$ and an alternative hypothesis $H_1$. The fact \"the new feature is affecting the SFLT in any way\" can be translated into 'the new feature is NOT affecting the SFLT in any way', this will mean that if it is not affecting the SFLT the mean SFLT should remain equal. This set the null hypothesis in the next way:\n",
    "\n",
    "$H_0:$ the mean of the SFLT with the new feature and the mean of the SFLT without the new feature are the same.\n",
    "\n",
    "and hence the alternative hypothesis will be:\n",
    "\n",
    "$H_1:$ the mean of the SFLT with the new feature and the mean of the SFLT without the new feature are different, and hence the new feature has an impact on the service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name, setup and explain the test you would perform to test this hypothesis.\n",
    "\n",
    "The most suitable statistical test in my opinion to test this hypothesis is the <b>Welch's t-test</b>. The test is a variation of the two-sample t-test; it is more robust by not assuming equal variance between the two populations from where we extract the sample mean. \n",
    "\n",
    "For using this test I will set the significance level at 0.05\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the set of formulas that you would need to validate the hypothesis.\n",
    "\n",
    "The set of formulas to validate this hypothesis are:\n",
    "\n",
    "$\\Huge t^*=\\frac{E[SFLT_0]-E[SFLT_1]}{\\sqrt{\\frac{s_{0}^2}{N_0}+\\frac{s_{1}^2}{N_1}}}$\n",
    "\n",
    "where:\n",
    "\n",
    "$E[SFLT_n]$ are the sample mean of each population\n",
    "\n",
    "$N_n$ are the sample size of each population\n",
    "\n",
    "$s_n$ are the standard deviation of each population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E[SFLT_0] 0.00986631273601\n",
      "E[SFLT_1] 0.00866427666406\n",
      "s_0 0.00988416640626\n",
      "s_1 0.00869044764773\n",
      "N_0 86400\n",
      "N_1 86400\n",
      "t_star 26.8456899552\n",
      "Degrees of freedom 170012.360418\n",
      "****************************\n",
      "NULL HYPOTHESIS NOT REJECTED\n",
      "****************************\n",
      "Ttest_indResult(statistic=array([ 26.8455346]), pvalue=array([  2.04114937e-158]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/.pyenv/versions/2.7.13/lib/python2.7/site-packages/ipykernel_launcher.py:39: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc178e87850>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'to_rgba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/home/javier/.pyenv/versions/2.7.13/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/javier/.pyenv/versions/2.7.13/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[0;32m/home/javier/.pyenv/versions/2.7.13/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'to_rgba'"
     ]
    }
   ],
   "source": [
    "#Implementation of the Welch's t-test\n",
    "\n",
    "\n",
    "SFLT_0 = np.random.exponential(scale=Y, size=(1,len(T))) #Sampled process for 24 hours without the new feature\n",
    "SFLT_1 = np.random.exponential(scale=Beta, size=(1,len(T))) #Sampled process for 24 with the new feature\n",
    "\n",
    "# Computing the important parameters of the sampled process\n",
    "E_SFLT_0 = np.mean(SFLT_0)\n",
    "E_SFLT_1 = np.mean(SFLT_1)\n",
    "\n",
    "std_SFLT_0 = np.std(SFLT_0)\n",
    "std_SFLT_1 = np.std(SFLT_1)\n",
    "\n",
    "N_0=len(T)\n",
    "N_1=N_0\n",
    "\n",
    "\n",
    "\n",
    "print 'E[SFLT_0]',E_SFLT_0\n",
    "print 'E[SFLT_1]',E_SFLT_1\n",
    "\n",
    "print 's_0', std_SFLT_0\n",
    "print 's_1', std_SFLT_1\n",
    "\n",
    "print 'N_0',N_0\n",
    "print 'N_1',N_1\n",
    "\n",
    "\n",
    "t_star = (E_SFLT_0-E_SFLT_1)/(np.sqrt(((std_SFLT_0**2)/N_0)+((std_SFLT_1**2)/N_1)))\n",
    "\n",
    "ddof_num = ((((std_SFLT_0**2)/N_0)+((std_SFLT_1**2)/N_1))**2)\n",
    "ddof_denom = ((std_SFLT_0**4)/((N_0**2)*(N_0-1)))+((std_SFLT_1**4)/((N_1**2)*(N_1-1)))\n",
    "Degrees_of_freedom = ddof_num/ddof_denom\n",
    "\n",
    "\n",
    "print 't_star',t_star\n",
    "print 'Degrees of freedom',Degrees_of_freedom\n",
    "\n",
    "s = np.random.standard_t(Degrees_of_freedom,1e6)\n",
    "\n",
    "\n",
    "\n",
    "if np.sum((s<=t_star).astype(int))<0.05:\n",
    "    print '************************'\n",
    "    print 'NULL HYPOTHESIS REJECTED'\n",
    "    print '************************'\n",
    "else:\n",
    "    print '****************************'\n",
    "    print 'NULL HYPOTHESIS NOT REJECTED'\n",
    "    print '****************************'\n",
    "\n",
    "#Using the inbuild Welch test for validation.\n",
    "print scipy.stats.ttest_ind(SFLT_0.T,SFLT_1.T,equal_var=False)\n",
    "\n",
    "\n",
    "# To have a visual reference\n",
    "plt.figure()\n",
    "plt.hist(s)\n",
    "plt.plot([t_star,t_star],[0,5e5],'r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should we roll back this feature? Why? Why not? Please provide a set of numbers that you used for this decision.\n",
    "\n",
    "Depending on the result on the previous test:\n",
    "\n",
    "If the null hypothesis is REJECTED: Rejecting the null hypothesis means that the at a 5% level of significance the data provide evidence that the new feature have an impact on the SFLT. The suggestion from a perspective of bussines intelligence department is to wait to release this feature until we have a better estimation of performance of the servers to provide better QoS to the users. A loading time is a critical value for the customer experience and any delay will generate people dropping not only this service but the whole freeletics application.\n",
    "\n",
    "If the null hypothesis is NOT REJECTED: means that the new feature do not have an inmpact on the SFLT and hence we are serving the customers at the same level as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a visualization that shows SFLT over time [hours] with appropriate confidence intervals.\n",
    "\n",
    "To provide the visualization of the SFLT with the new feature over time with confidence intervals the first thing to do is to bin the given process in one hour bin and compute the mean of that period of time and the confidence interval.\n",
    "\n",
    "The code below summarize the procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confidence_interval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fc75ba6f9dd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstd_SFLT_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmargin_of_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mconfidence_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlocal_SFLT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSFLT_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSeconds\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mSeconds\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confidence_interval' is not defined"
     ]
    }
   ],
   "source": [
    "Hours = 24\n",
    "Seconds = 3600\n",
    "z_critical= scipy.stats.expon.ppf(q=0.99,scale=Beta)\n",
    "\n",
    "mean_SFLT_1=[]\n",
    "std_SFLT_1=[]\n",
    "margin_of_error=[]\n",
    "del confidence_interval\n",
    "for i in range(Hours):\n",
    "    local_SFLT = SFLT_1.T[Seconds*i:Seconds*(i+1)]\n",
    "    mean_SFLT_1.append(np.mean(local_SFLT))\n",
    "    std_SFLT_1.append(np.std(local_SFLT))\n",
    "    margin_of_error.append(z_critical[0] * (np.std(local_SFLT)/math.sqrt(Seconds)))\n",
    "    \n",
    "\n",
    "mean_SFLT_1 = np.array(mean_SFLT_1)\n",
    "std_SFLT_1 = np.array(std_SFLT_1)\n",
    "margin_of_error = np.array(margin_of_error)\n",
    "\n",
    "confidence_interval = (mean_SFLT_1 - margin_of_error,\n",
    "                           mean_SFLT_1 + margin_of_error)  \n",
    "    \n",
    "# Definition of the figure.\n",
    "figid = plt.figure(1,figsize=(20, 10), dpi=180)\n",
    "# Definition of the matrix of plots. In this case the situation is more complex that is why I need to define a\n",
    "# matrix. It will be a dim[2x3] matrix.\n",
    "gs = grds.GridSpec(1,1)\n",
    "ax1 = plt.subplot(gs[0, :])\n",
    "\n",
    "ax1.plot(mean_SFLT_1)\n",
    "ax1.plot(mean_SFLT_1,'r.')\n",
    "ax1.plot(mean_SFLT_1-margin_of_error,'r')\n",
    "ax1.plot(mean_SFLT_1+margin_of_error,'r')\n",
    "\n",
    "# Setting the xlabel with the desired parameters\n",
    "override = {\n",
    "    'fontsize'            : '14',\n",
    "    'verticalalignment'   : 'top',\n",
    "    'horizontalalignment' : 'center'\n",
    "    }\n",
    "ax1.set_xlabel('t[hours]',override)\n",
    "ax1.set_ylabel('SFLT[seconds]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: is there a correlation between traffic and SFLT? How would you prove it? What would that indicate?\n",
    "\n",
    "Calculating the correlation coefficient of the two signals (cell below), Traffic and SFLT, it is possible to see that the correlation coefficient is pretty low. This means that the two signals are highly uncorrelated (independent) and indicates that we are far from reaching the state in which the waiting time is driven by the arrivals of the customer (that is having a $\\rho \\approxeq 1$ ). For values like the one used here of $\\rho = 0.8$ the system is still in a state in which the arrivals can be easily managed by the server and hence the delays fall whithin the the distribution of the own capabilities of the server rather than on the distribution of the load (arrivals) of the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient: 0.00125025545461\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print 'Correlation coefficient:',np.corrcoef(Traffic,SFLT_1[0,:])[1,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
